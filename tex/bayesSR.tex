\chapter{Super Resolução Bayesiana}
\label{chap:srbayes}
O método de super resolução desenvolvido no trabalho de Tipping e Bishop \cite{tipping2003bayesian} é um método probabilístico para a obtenção de uma imagem de alta resolução
a partir de um conjunto de imagens de baixa resolução de uma mesma cena.
Esse conjunto de imagens de baixa resolução poderiam ser retirados de quadros de um
vídeo produzido por uma câmera de segurança que fica parada em relação ao objeto
observado, por exemplo.

Pode-se dizer que a abordagem usada neste método é uma expansão do método de máxima
verossimilhança descrito na seção \ref{sec:metodosprob}.
O método de super-resolução Bayesiana adiciona uma densidade de probabilidade como conhecimento a priori da imagem para restringir a quantidade de soluções possíveis do problema, contornando assim um dos problemas da abordagem de máxima verossimilhança.
A adição de uma densidade de probabilidade \emph{a priori}, converte a abordagem de máxima verossimilhança em uma abordagem de máximo \emph{a posteriori} (MAP).

se vale do método de inferência Bayesiana para obter uma imagem de alta resolução a partir de várias imagens de baixa resolução.
Através de um método de inferência Bayesiana, é possível obter uma estimativa de valores desconhecidos (como a imagem de alta resolução) usando um conhecimento a priori que se tem desses dados e informações que já estão disponíveis(no caso, as imagens de baixa resolução) \cite{therrien2011probability}.

Sabendo disso, há a necessidade de formular uma distribuição a priori que represente as características estatísticas da imagem que pretendemos estimar a partir dos dados.
A distribuição de probabilidade a priori escolhida para a imagem é uma gaussiana como descrita a seguir:

\begin{gather}
	p(\mathbf{x}) = \mathcal{N}(\mathbf{x} | 0, \mathbf{Z}_x) \\ 
	Z_x(i,j) = A \exp \left\{ - \frac{\|\mathbf{v}_i - \mathbf{v}_j \|^2}{r^2} \right\}
\end{gather}

Onde $A$ é uma constante, e $r$ determina o quanto cada ponto da imagem de alta resolução depende dos pontos vizinhos.
Expandindo a função densidade de probabilidade $p(\mathbf{x})$ temos:

\begin{equation}
	p(\mathbf{x}) = \frac{1}{\sqrt{(2\pi)^N |\mathbf{Z}_x|}}\exp{-\tfrac{1}{2} \mathbf{x}^T \mathbf{Z}^{-1}_x \mathbf{x}}
% ISSUE: Corrigir esta equação.
\end{equation}

Este tipo de distribuição não é o ideal, visto que se definirmos $r=1$, estaríamos dizendo que a maioria dos valores dos pontos da imagem de de alta resolução estão contidos no intervalo $[-1,1]$, o que não condiz com a realidade.
No entanto, o uso desta distribuição a priori será mantido no desenvolvimento deste trabalho pela conveniência proporcionada pela função de probabilidade Gaussiana, que facilita algumas manipulações -- como aplicação de logaritmos naturais --  utilizadas a seguir.

Ciente da relação entre a imagem original e as imagens de baixa resolução, podemos escrever a probabilidade a posteriori das imagens de baixa resolução como:

\begin{equation}
	\label{eq:posterior0}
	p(\mathbf{y}^{(k)} | \mathbf{x}, \mathbf{s}_k, \theta_k, \gamma) = 
	\left(\frac{\beta}{2\pi}\right)^{M/2}
	\exp \left\{ -\frac{\beta}{2} \| \mathbf{y}^{(k)} - \mathbf{W}^{(k)} \mathbf{x} \|^2 \right\}.
\end{equation}

Note que esta distribuição é condicionada na imagem de alta resolução e nos parâmetros de degradação, dados que são desconhecidos em um situação real.

Podemos usar o Teorema de Bayes para isolar a imagem original $\mathbf{x}$, ao que obtemos:

\begin{gather}
	\label{eq:posteriordist}
	p(\mathbf{x}|\{\mathbf{y}^{(k)},\mathbf{s}_k,\theta_k\}, \gamma) = 
	\frac{p(\mathbf{x})\prod^K_{k=1} p(\mathbf{y}^{(k)}|\mathbf{x},\mathbf{s}_k,\theta_k, \gamma)}
	{p(\{\mathbf{y}^{(k)}\}|\{\mathbf{s}_k,\mathbf{\theta}_k\},\gamma)} \\
	= \mathcal{N}(\boldsymbol{\mu},\mathbf{\Sigma}) \\
	\mathbf{ \Sigma }= \left[\mathbf{Z}^{-1}_x + \beta \left( \sum^K_{k = 1} \mathbf{W}^{(k)^T} \mathbf{W}^{(k)} \right) \right]^{-1} \\
	\boldsymbol{\mu} = \beta \mathbf{ \Sigma } \left( \sum^K_{k=1} \mathbf{W}^{(k)^T}\mathbf{y}^{(k)} \right).
\end{gather}

Esta função de probabilidade já poderia ser utilizada para inferir a imagem de alta resolução.
Para isso, bastaria encontrar o valor de $\mathbf{x}$ que maximiza o numerador em (\ref{eq:posteriordist}). entretanto, isso exigiria saber os valores dos parâmetros de degradação ($\gamma$, $\theta_k$, $\mathbf{\theta}_k$).
Como esses parâmetros não estão disponíveis, eles também terão de ser estimados a partir das imagens de baixa resolução $\mathbf{y}_k$. 

A solução proposta no artigo é marginalizar $\mathbf{x}$ em (\ref{eq:posterior0}) para que ele não seja mais uma variável na função. O resultado disto é a seguinte distribuição:

\begin{align}
	\label{eq:parameter}
	\log p(\mathrm{y}|\{\mathbf{s}_k,\theta_k\}, \gamma) &= -\frac{1}{2}\left[\beta \sum^K_{k=1} \|\mathbf{y}^{(k)} - \mathbf{W}^{(k)}\boldsymbol{\mu}\|
    + \boldsymbol{\mu}^T\mathbf{Z}_x \boldsymbol{\mu} \right. \nonumber \\
    &\qquad \left.\vphantom{\int_t} + \log |\mathbf{Z}_x| - \log{|\Sigma |} - KM \log \beta \right].
\end{align}

Onde y é o conjunto de todas as imagens de baixa resolução $\mathbf{y}_k$.

Em uma situação ideal, a melhor estimativa dos valores dos parâmetros de degradação é a que maximiza a função de verossimilhança em (\ref{eq:parameter}).
Tendo a estimativa desses valores, podemos então usá-los em (\ref{eq:posteriordist}) para procurar pelo vetor $\mathbf{x}$ que maximiza aquela função de verossimilhança.

Um fato que se constatou empiricamente na tentativa de calcular os valores da função de verossimilhança é que as probabilidades são muito pequenas ao ponto de estarem fora do intervalo de precisão de uma variável do tipo ponto flutuante.
Os valores também variam muito pouco ao longo do espaço vetorial de $\mathbf{x}$ o que dificultaria o uso de métodos iterativos para encontrar o ponto de máximo da função.

Para resolver isso, aplicou-se o logaritmo natural à função. Isso resolveu o problema da escala e da variação.
Além disso eliminou os exponenciais e os produtos, facilitando o cálculo do gradiente e Jacobiano da função.

\begin{gather}
	L(\mathbf{x}) = -\frac{1}{2} \left\{ \sum^K_{k=1} \|\mathbf{y}^{(k)} - \mathbf{W}^{(k)} \mathbf{x} \|^2 + \mathbf{x}^T\mathbf{Z}^{-1}_x\mathbf{x} - KM\mathrm{ln}(\beta) - \mathrm{ln}|\mathbf{Z}_x| \right\} \\ 
	L'(\mathbf{x}) =  \sum^K_{k=1}  (\mathbf{y}^{(k)} - \mathbf{W}^{(k)}\mathbf{x})(\mathbf{W}^{(k)})^T  - \frac{1}{2}(\mathbf{Z}^{-1}_x + (\mathbf{Z}^{-1}_x)^T)\mathbf{x}  \\
	L''(\mathbf{x}) =  -\sum^K_{k=1} (\mathbf{W}^{(k)})^T\mathbf{W}^{(k)} - \frac{1}{2}(\mathbf{Z}^{-1}_x - (\mathbf{Z}^{-1}_x)^T)^T
\end{gather}


